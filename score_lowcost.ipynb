{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/apache/spark/tree/master/examples/src/main/python\n",
    "\n",
    "https://datascience-enthusiast.com/Python/pythonindex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(\"metastore_db/db.lck\")\n",
    "    os.remove(\"metastore_db/dbex.lck\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def build_spark_session(app_name, memory='4g', executors=4):\n",
    "    return SparkSession.builder\\\n",
    "                      .appName(app_name)\\\n",
    "                      .config('spark.executor.memory', memory)\\\n",
    "                      .config('spark.executor.instances', executors)\\\n",
    "                      .getOrCreate()\n",
    "\n",
    "spark_session = build_spark_session(app_name='ok-google')\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l'objectif est de predire l'appentence des clients a des transport lowcoast.\n",
    "Pour cela, nous utiliserons la librairie Ml de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perimetre: représente les identifaints des clients accessible à l'étude.\n",
    "histo_client: represente l'historique des données clients sur une période donnée\n",
    "histo_train: represente l'historique des données de commandes trains.\n",
    "histo_lowcost: represente l'historique des données de client lowcost (défini avec le métier).\n",
    "visites: représente l'historique des données de navigation des clients sur le site."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 - lire les fichiers de données\n",
    "2 - identifier les variables continues et transformer leurs modalités en double.\n",
    "3 - joindre les differentes sources de données en se basant sur les données du périmètre (tous les individus du périmèetre devront apparaitre dans la jointure avec des valeurs NULL si nécessaire pour les colonnes en provenance d'autres sources).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - joindre les dataframe sur la clé ID_CLIENT en concervant tous les clients du périmètre.\n",
    "2 - compter le nombre de ID_CLIENT et vérifier qu'il correspond aux nombre d'ID_CLIENT dans la variable perimètre.\n",
    "3 - Caster les variables continues en double et sauvergarder alors le df obtenu dans le repertoire data sur le cluster.\n",
    "4 - Pour les variables catégorielles, créer une nouvelle variable qui prend la modalité de la variable courante si elle existe et \"NA\" sinon.\n",
    "5- Verifier la cohérence des variables continue. Par exemple pour une variable comme age mettre à -1 tous les ages <0 ou>120ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perimetre = spark_session.read.csv(\"data/sample_perimetre.csv\", header=True)\n",
    "histo_client_raw = spark_session.read.csv(\"data/sample_histo_client.csv\", header=True)\n",
    "histo_train_raw = spark_session.read.csv(\"data/sample_histo_train.csv\", header=True)\n",
    "histo_lowcost_raw = spark_session.read.csv(\"data/sample_histo_lowcost.csv\", header=True)\n",
    "visites_raw = spark_session.read.csv(\"data/sample_visites.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histo_client_raw.select(\"LBL_SEG_COMPORTEMENTAL\").distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour recuperer la dimension et les variables d'un dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fonction qui permet d'avoir la taille d'un dataframe ainsi que les différentes variables en son sein*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du DataFrame : (1084162, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[ID_CLIENT: string, anciennete: string, recence_cmd: string, AGE: string, LBL_STATUT_CLT: string, LBL_GEO_AIR: string, LBL_GRP_SEGMENT_NL: string, LBL_SEG_COMPORTEMENTAL: string, LBL_GEO_TRAIN: string, LBL_SEGMENT_ANTICIPATION: string, FLG_CMD_CARTE_1225: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dtail_data(data):\n",
    "    print (\"Taille du DataFrame : {}\".format((data.count(),len(data.columns))))\n",
    "    return data #affiche les colonnes du dataframe\n",
    "\n",
    "dtail_data(histo_client_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Transformations sur les dataframes,conversions des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ecrire une fonction pour transformer les features quantitatives (\"anciennete\", \"recence_cmd\", \"AGE\", etc..) en float*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
    "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
    "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225']\n",
    "\n",
    "client_col_to_cast=[\"anciennete\",\"recence_cmd\",\"AGE\"]\n",
    "\n",
    "def cast_columns_of_df(df, cols_to_cast, col_to_keep, cast_type='double'):\n",
    "    \"\"\"cast continuous columns into double since all columns are \"\"\"\n",
    "    return df.select(col_to_keep + [(df[feature].cast('double'))\n",
    "                    for feature in cols_to_cast if 'ID_CLIENT' not in feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID_CLIENT='000843db32fbaecfbb047ca0bb04b1f9f4d9425a', LBL_STATUT_CLT='Grand', LBL_GEO_AIR='Aéroports de Paris Orly', LBL_SEG_COMPORTEMENTAL='Chasseurs Bons Plans', LBL_GEO_TRAIN='Paris', LBL_GRP_SEGMENT_NL='Spectateur', LBL_SEGMENT_ANTICIPATION='Mixte', FLG_CMD_CARTE_1225='0', anciennete=1550.0, recence_cmd=36.0, AGE=None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_columns_of_df(histo_client_raw,client_col_to_cast,client_cols_to_keep).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
    "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
    "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225']\n",
    "\n",
    "def cast_columns_of_df(df, cols_to_cast, col_to_keep, cast_type='double'):\n",
    "    \"\"\"cast continuous columns into double since all columns are \"\"\"\n",
    "    return df.select(col_to_keep + [(df[feature].cast('double'))\n",
    "                    for feature in cols_to_cast if 'ID_CLIENT' not in feature])\n",
    "\n",
    "histo_train = cast_columns_of_df(histo_train_raw, histo_train_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "histo_lowcost = cast_columns_of_df(histo_lowcost_raw, histo_lowcost_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "visites = cast_columns_of_df(visites_raw, visites_raw.columns,\n",
    "                             [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "histo_client = cast_columns_of_df(histo_client_raw,\n",
    "                                  [\"anciennete\", \"recence_cmd\", \"AGE\"],\n",
    "                                  client_cols_to_keep,\n",
    "                                 cast_type='double')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Faire une jointure entre les informations des différentes tables. NB: on conservera tous les clients de la table perimetre. En effet, ce sont les cleints qu'on souhaite scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_by_dataframe (args ,attribut_de_jointure , type_de_jointure):\n",
    "    data = args[0]\n",
    "    for i in list(range(1,len(args))):\n",
    "        data = data.join(args[i] ,on  = attribut_de_jointure , how  = type_de_jointure )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENT</th>\n",
       "      <th>nb_od</th>\n",
       "      <th>mean_nb_passagers</th>\n",
       "      <th>mean_duree_voyage</th>\n",
       "      <th>mean_mt_voyage</th>\n",
       "      <th>mean_tarif_loisir</th>\n",
       "      <th>mean_classe_1</th>\n",
       "      <th>mean_pointe</th>\n",
       "      <th>mean_depart_we</th>\n",
       "      <th>flg_cmd_lowcost</th>\n",
       "      <th>...</th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "      <th>LBL_GEO_AIR</th>\n",
       "      <th>LBL_SEG_COMPORTEMENTAL</th>\n",
       "      <th>LBL_GEO_TRAIN</th>\n",
       "      <th>LBL_GRP_SEGMENT_NL</th>\n",
       "      <th>LBL_SEGMENT_ANTICIPATION</th>\n",
       "      <th>FLG_CMD_CARTE_1225</th>\n",
       "      <th>anciennete</th>\n",
       "      <th>recence_cmd</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000843db32fbaecfbb047ca0bb04b1f9f4d9425a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274.666667</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Grand</td>\n",
       "      <td>Aéroports de Paris Orly</td>\n",
       "      <td>Chasseurs Bons Plans</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Spectateur</td>\n",
       "      <td>Mixte</td>\n",
       "      <td>0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001338752ea32d9de129c8f8bdf3e2224cf0bd71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>128.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Grand</td>\n",
       "      <td>Aéroport de Marseille Provence  (MRS)</td>\n",
       "      <td>Comportement Pro</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Spectateur</td>\n",
       "      <td>Anticipateur</td>\n",
       "      <td>0</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003fb9dca8de374386d0fa97b570950583111931</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>248.250000</td>\n",
       "      <td>46.475000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Moyen moins</td>\n",
       "      <td>Aéroport de Lyon - Saint Exupéry</td>\n",
       "      <td>Rythmes scolaires</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Spectateur</td>\n",
       "      <td>Peu Anticipateur</td>\n",
       "      <td>1</td>\n",
       "      <td>395.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ID_CLIENT  nb_od  mean_nb_passagers  \\\n",
       "0  000843db32fbaecfbb047ca0bb04b1f9f4d9425a    1.0                1.0   \n",
       "1  001338752ea32d9de129c8f8bdf3e2224cf0bd71    1.0                1.0   \n",
       "2  003fb9dca8de374386d0fa97b570950583111931    3.0                1.5   \n",
       "\n",
       "   mean_duree_voyage  mean_mt_voyage  mean_tarif_loisir  mean_classe_1  \\\n",
       "0         274.666667       58.666667                0.0            0.0   \n",
       "1         232.000000      128.200000                1.0            1.0   \n",
       "2         248.250000       46.475000                0.5            0.0   \n",
       "\n",
       "   mean_pointe  mean_depart_we  flg_cmd_lowcost  ...   LBL_STATUT_CLT  \\\n",
       "0         0.00            0.00              NaN  ...            Grand   \n",
       "1         0.00            0.00              NaN  ...            Grand   \n",
       "2         0.25            0.25              1.0  ...      Moyen moins   \n",
       "\n",
       "                             LBL_GEO_AIR  LBL_SEG_COMPORTEMENTAL  \\\n",
       "0                Aéroports de Paris Orly    Chasseurs Bons Plans   \n",
       "1  Aéroport de Marseille Provence  (MRS)        Comportement Pro   \n",
       "2       Aéroport de Lyon - Saint Exupéry       Rythmes scolaires   \n",
       "\n",
       "   LBL_GEO_TRAIN LBL_GRP_SEGMENT_NL LBL_SEGMENT_ANTICIPATION  \\\n",
       "0          Paris         Spectateur                    Mixte   \n",
       "1      Marseille         Spectateur             Anticipateur   \n",
       "2           Lyon         Spectateur         Peu Anticipateur   \n",
       "\n",
       "  FLG_CMD_CARTE_1225 anciennete recence_cmd   AGE  \n",
       "0                  0     1550.0        36.0   NaN  \n",
       "1                  0     1667.0        25.0  35.0  \n",
       "2                  1      395.0        15.0  25.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = join_by_dataframe([perimetre,histo_train,histo_lowcost , visites, histo_client]\n",
    "                          , attribut_de_jointure = 'ID_CLIENT' ,\n",
    "                          type_de_jointure = 'left_outer')\n",
    "datafin = data3.toPandas()\n",
    "datafin.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Verification de la taille de **perimetre** et le **New dataframe** apres jointure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perimetre.count() == data3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Le jeu de données data3 contient 24 variables  et 1084217 observation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du DataFrame : (1084217, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[ID_CLIENT: string, nb_od: double, mean_nb_passagers: double, mean_duree_voyage: double, mean_mt_voyage: double, mean_tarif_loisir: double, mean_classe_1: double, mean_pointe: double, mean_depart_we: double, flg_cmd_lowcost: double, flg_track_nl_lowcost: double, flg_track_nl: double, days_since_last_visit: double, tx_conversion: double, LBL_STATUT_CLT: string, LBL_GEO_AIR: string, LBL_SEG_COMPORTEMENTAL: string, LBL_GEO_TRAIN: string, LBL_GRP_SEGMENT_NL: string, LBL_SEGMENT_ANTICIPATION: string, FLG_CMD_CARTE_1225: string, anciennete: double, recence_cmd: double, AGE: double]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtail_data(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID_CLIENT',\n",
       " 'nb_od',\n",
       " 'mean_nb_passagers',\n",
       " 'mean_duree_voyage',\n",
       " 'mean_mt_voyage',\n",
       " 'mean_tarif_loisir',\n",
       " 'mean_classe_1',\n",
       " 'mean_pointe',\n",
       " 'mean_depart_we',\n",
       " 'flg_cmd_lowcost',\n",
       " 'flg_track_nl_lowcost',\n",
       " 'flg_track_nl',\n",
       " 'days_since_last_visit',\n",
       " 'tx_conversion',\n",
       " 'LBL_STATUT_CLT',\n",
       " 'LBL_GEO_AIR',\n",
       " 'LBL_SEG_COMPORTEMENTAL',\n",
       " 'LBL_GEO_TRAIN',\n",
       " 'LBL_GRP_SEGMENT_NL',\n",
       " 'LBL_SEGMENT_ANTICIPATION',\n",
       " 'FLG_CMD_CARTE_1225',\n",
       " 'anciennete',\n",
       " 'recence_cmd',\n",
       " 'AGE']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = perimetre.join(histo_train,on = \"ID_CLIENT\",how = \"left_outer\")\n",
    "#data2 = data1.join(histo_lowcost,on = \"ID_CLIENT\",how = \"left_outer\")\n",
    "#data3 = data2.join(visites,on = \"ID_CLIENT\",how = \"left_outer\").join(histo_client,on = \"ID_CLIENT\",how = \"left_outer\")\n",
    "#datafin = data3.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combien a t'on de features quatitatives, qualitatives ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fonction qui permet d'obtenir le nombre et les différentes variable et  qualitative,quantitative*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('nb_od', 'double'),\n",
       " ('mean_nb_passagers', 'double'),\n",
       " ('mean_duree_voyage', 'double'),\n",
       " ('mean_mt_voyage', 'double'),\n",
       " ('mean_tarif_loisir', 'double'),\n",
       " ('mean_classe_1', 'double'),\n",
       " ('mean_pointe', 'double'),\n",
       " ('mean_depart_we', 'double'),\n",
       " ('flg_cmd_lowcost', 'double'),\n",
       " ('flg_track_nl_lowcost', 'double'),\n",
       " ('flg_track_nl', 'double'),\n",
       " ('days_since_last_visit', 'double'),\n",
       " ('tx_conversion', 'double'),\n",
       " ('LBL_STATUT_CLT', 'string'),\n",
       " ('LBL_GEO_AIR', 'string'),\n",
       " ('LBL_SEG_COMPORTEMENTAL', 'string'),\n",
       " ('LBL_GEO_TRAIN', 'string'),\n",
       " ('LBL_GRP_SEGMENT_NL', 'string'),\n",
       " ('LBL_SEGMENT_ANTICIPATION', 'string'),\n",
       " ('FLG_CMD_CARTE_1225', 'string'),\n",
       " ('anciennete', 'double'),\n",
       " ('recence_cmd', 'double'),\n",
       " ('AGE', 'double')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr de variables qualitatives: 8 \n",
      " Variables qualitatives :['flg_cmd_lowcost', 'ID_CLIENT', 'LBL_STATUT_CLT', 'LBL_GEO_AIR', 'LBL_SEG_COMPORTEMENTAL', 'LBL_GEO_TRAIN', 'LBL_GRP_SEGMENT_NL', 'LBL_SEGMENT_ANTICIPATION', 'FLG_CMD_CARTE_1225'] \n",
      " \n",
      " Nbr de variables quatitatives: 16 \n",
      " Variables quantitatives: ['nb_od', 'mean_nb_passagers', 'mean_duree_voyage', 'mean_mt_voyage', 'mean_tarif_loisir', 'mean_classe_1', 'mean_pointe', 'mean_depart_we', 'flg_cmd_lowcost', 'flg_track_nl_lowcost', 'flg_track_nl', 'days_since_last_visit', 'tx_conversion', 'anciennete', 'recence_cmd', 'AGE']\n"
     ]
    }
   ],
   "source": [
    "continuous = []\n",
    "quali = [\"flg_cmd_lowcost\"]\n",
    "def get_quali_quant(data):\n",
    "    quantitative = 0\n",
    "    qualitative = 0\n",
    "    data = data.dtypes\n",
    "    for i in data:\n",
    "        if i[1] ==  \"double\":\n",
    "            continuous.append(i[0])\n",
    "            quantitative += 1\n",
    "        else :\n",
    "            quali.append(i[0])\n",
    "            qualitative += 1\n",
    "    print (\"Nbr de variables qualitatives: {} \\n Variables qualitatives :{} \\n \\n Nbr de variables quatitatives: {} \\n Variables quantitatives: {}\".format(qualitative,quali,quantitative,continuous))\n",
    "    \n",
    "get_quali_quant(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelles sont les differentes modalites de la feature LBL_STATUT_CLT ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fonction qui permet d'afficher les différentes modalités d'un dataframa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(LBL_STATUT_CLT='Moyen moins'),\n",
       " Row(LBL_STATUT_CLT='Non present dans la base a cette date'),\n",
       " Row(LBL_STATUT_CLT='Nouveau prospect'),\n",
       " Row(LBL_STATUT_CLT='Prospect'),\n",
       " Row(LBL_STATUT_CLT='Tres petit'),\n",
       " Row(LBL_STATUT_CLT=None),\n",
       " Row(LBL_STATUT_CLT='Petit'),\n",
       " Row(LBL_STATUT_CLT='Inactif'),\n",
       " Row(LBL_STATUT_CLT='Nouveau actif'),\n",
       " Row(LBL_STATUT_CLT='Grand'),\n",
       " Row(LBL_STATUT_CLT='Tres grand'),\n",
       " Row(LBL_STATUT_CLT='Moyen plus')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modalite(data,var):\n",
    "    return data.select(var).distinct().collect()\n",
    "\n",
    "modalite(data3,\"LBL_STATUT_CLT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Sauvegarde du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T08:20:02.421818Z",
     "start_time": "2019-10-31T08:20:02.419233Z"
    }
   },
   "outputs": [],
   "source": [
    "#data3.write.save(\"data/data3.csv\",format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_od',\n",
       " 'mean_nb_passagers',\n",
       " 'mean_duree_voyage',\n",
       " 'mean_mt_voyage',\n",
       " 'mean_tarif_loisir',\n",
       " 'mean_classe_1',\n",
       " 'mean_pointe',\n",
       " 'mean_depart_we',\n",
       " 'flg_cmd_lowcost',\n",
       " 'flg_track_nl_lowcost',\n",
       " 'flg_track_nl',\n",
       " 'days_since_last_visit',\n",
       " 'tx_conversion',\n",
       " 'anciennete',\n",
       " 'recence_cmd',\n",
       " 'AGE']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelles sont les features avec valeurs manquantes remplacer les valeurs manquantes par -1 pour toutes les features ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T08:20:02.539919Z",
     "start_time": "2019-10-31T08:20:02.423875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'ID_CLIENT'),\n",
       " (1, 'nb_od'),\n",
       " (2, 'mean_nb_passagers'),\n",
       " (3, 'mean_duree_voyage'),\n",
       " (4, 'mean_mt_voyage'),\n",
       " (5, 'mean_tarif_loisir'),\n",
       " (6, 'mean_classe_1'),\n",
       " (7, 'mean_pointe'),\n",
       " (8, 'mean_depart_we'),\n",
       " (9, 'flg_cmd_lowcost'),\n",
       " (10, 'flg_track_nl_lowcost'),\n",
       " (11, 'flg_track_nl'),\n",
       " (12, 'days_since_last_visit'),\n",
       " (13, 'tx_conversion'),\n",
       " (14, 'LBL_STATUT_CLT'),\n",
       " (15, 'LBL_GEO_AIR'),\n",
       " (16, 'LBL_SEG_COMPORTEMENTAL'),\n",
       " (17, 'LBL_GEO_TRAIN'),\n",
       " (18, 'LBL_GRP_SEGMENT_NL'),\n",
       " (19, 'LBL_SEGMENT_ANTICIPATION'),\n",
       " (20, 'FLG_CMD_CARTE_1225'),\n",
       " (21, 'anciennete'),\n",
       " (22, 'recence_cmd'),\n",
       " (23, 'AGE')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of columns\n",
    "list(enumerate(data3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T17:21:23.165746Z",
     "start_time": "2019-10-30T17:20:53.109330Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "continuous.remove(\"flg_cmd_lowcost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_od',\n",
       " 'mean_nb_passagers',\n",
       " 'mean_duree_voyage',\n",
       " 'mean_mt_voyage',\n",
       " 'mean_tarif_loisir',\n",
       " 'mean_classe_1',\n",
       " 'mean_pointe',\n",
       " 'mean_depart_we',\n",
       " 'flg_track_nl_lowcost',\n",
       " 'flg_track_nl',\n",
       " 'days_since_last_visit',\n",
       " 'tx_conversion',\n",
       " 'anciennete',\n",
       " 'recence_cmd',\n",
       " 'AGE']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T08:22:31.568984Z",
     "start_time": "2019-10-31T08:20:12.299141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.515022865927351,\n",
       " 1.2363232480537965,\n",
       " 152.64514973822276,\n",
       " 43.19983674929222,\n",
       " 0.3599612090605884,\n",
       " 0.20166499766517768,\n",
       " 0.3525474532671343,\n",
       " 0.321143304334669,\n",
       " 0.13100876267904052,\n",
       " 0.6506145379939793,\n",
       " 16.574795970884495,\n",
       " 0.34099569046665423,\n",
       " 1707.0163204391963,\n",
       " 28.963997587586228,\n",
       " 36.77269796022761]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue_columns = data3.columns[1:]\n",
    "#d_frame = data3\n",
    "datafin2 = [data3.select(f.mean(feature)).collect()[0][0]  for feature in continuous]\n",
    "datafin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T08:22:32.075845Z",
     "start_time": "2019-10-31T08:22:31.573766Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_frame = data3.select([f.when(data3[feature].isNotNull(),data3[feature])\\\n",
    "           .otherwise(-1).alias(feature) for i,feature in enumerate(client_cols_to_keep)]\\\n",
    "          +[f.when(data3[feature].isNotNull(),data3[feature])\\\n",
    "            .otherwise(datafin2[i]).alias(feature) for i,feature in enumerate(continuous)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T08:23:01.310322Z",
     "start_time": "2019-10-31T08:22:32.081678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENT</th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "      <th>LBL_GEO_AIR</th>\n",
       "      <th>LBL_SEG_COMPORTEMENTAL</th>\n",
       "      <th>LBL_GEO_TRAIN</th>\n",
       "      <th>LBL_GRP_SEGMENT_NL</th>\n",
       "      <th>LBL_SEGMENT_ANTICIPATION</th>\n",
       "      <th>FLG_CMD_CARTE_1225</th>\n",
       "      <th>nb_od</th>\n",
       "      <th>mean_nb_passagers</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_classe_1</th>\n",
       "      <th>mean_pointe</th>\n",
       "      <th>mean_depart_we</th>\n",
       "      <th>flg_track_nl_lowcost</th>\n",
       "      <th>flg_track_nl</th>\n",
       "      <th>days_since_last_visit</th>\n",
       "      <th>tx_conversion</th>\n",
       "      <th>anciennete</th>\n",
       "      <th>recence_cmd</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000843db32fbaecfbb047ca0bb04b1f9f4d9425a</td>\n",
       "      <td>Grand</td>\n",
       "      <td>Aéroports de Paris Orly</td>\n",
       "      <td>Chasseurs Bons Plans</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Spectateur</td>\n",
       "      <td>Mixte</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.650615</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.772698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001338752ea32d9de129c8f8bdf3e2224cf0bd71</td>\n",
       "      <td>Grand</td>\n",
       "      <td>Aéroport de Marseille Provence  (MRS)</td>\n",
       "      <td>Comportement Pro</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Spectateur</td>\n",
       "      <td>Anticipateur</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.650615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003fb9dca8de374386d0fa97b570950583111931</td>\n",
       "      <td>Moyen moins</td>\n",
       "      <td>Aéroport de Lyon - Saint Exupéry</td>\n",
       "      <td>Rythmes scolaires</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Spectateur</td>\n",
       "      <td>Peu Anticipateur</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>395.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004efa6652e570ef68944b780738e159fbf2aeb5</td>\n",
       "      <td>Moyen moins</td>\n",
       "      <td>Aéroport de Lyon - Saint Exupéry</td>\n",
       "      <td>Sans contraintes</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Spectateur</td>\n",
       "      <td>Tres Anticipateur</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.650615</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005dd0b718a8f4598ae3044e60f9c20222eb3a35</td>\n",
       "      <td>Petit</td>\n",
       "      <td>Aéroport de Strasbourg</td>\n",
       "      <td>Sans contraintes</td>\n",
       "      <td>Metz</td>\n",
       "      <td>Endormi</td>\n",
       "      <td>Non Anticipateur</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.650615</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3005.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ID_CLIENT LBL_STATUT_CLT  \\\n",
       "0  000843db32fbaecfbb047ca0bb04b1f9f4d9425a          Grand   \n",
       "1  001338752ea32d9de129c8f8bdf3e2224cf0bd71          Grand   \n",
       "2  003fb9dca8de374386d0fa97b570950583111931    Moyen moins   \n",
       "3  004efa6652e570ef68944b780738e159fbf2aeb5    Moyen moins   \n",
       "4  005dd0b718a8f4598ae3044e60f9c20222eb3a35          Petit   \n",
       "\n",
       "                             LBL_GEO_AIR LBL_SEG_COMPORTEMENTAL LBL_GEO_TRAIN  \\\n",
       "0                Aéroports de Paris Orly   Chasseurs Bons Plans         Paris   \n",
       "1  Aéroport de Marseille Provence  (MRS)       Comportement Pro     Marseille   \n",
       "2       Aéroport de Lyon - Saint Exupéry      Rythmes scolaires          Lyon   \n",
       "3       Aéroport de Lyon - Saint Exupéry       Sans contraintes          Lyon   \n",
       "4                 Aéroport de Strasbourg       Sans contraintes          Metz   \n",
       "\n",
       "  LBL_GRP_SEGMENT_NL LBL_SEGMENT_ANTICIPATION FLG_CMD_CARTE_1225  nb_od  \\\n",
       "0         Spectateur                    Mixte                  0    1.0   \n",
       "1         Spectateur             Anticipateur                  0    1.0   \n",
       "2         Spectateur         Peu Anticipateur                  1    3.0   \n",
       "3         Spectateur        Tres Anticipateur                  0    1.0   \n",
       "4            Endormi         Non Anticipateur                  0    1.0   \n",
       "\n",
       "   mean_nb_passagers    ...      mean_classe_1  mean_pointe  mean_depart_we  \\\n",
       "0                1.0    ...                0.0         0.00            0.00   \n",
       "1                1.0    ...                1.0         0.00            0.00   \n",
       "2                1.5    ...                0.0         0.25            0.25   \n",
       "3                1.0    ...                0.5         0.00            0.50   \n",
       "4                1.0    ...                0.0         0.50            0.50   \n",
       "\n",
       "   flg_track_nl_lowcost  flg_track_nl  days_since_last_visit  tx_conversion  \\\n",
       "0              0.131009      0.650615                    8.0       0.111111   \n",
       "1              0.131009      0.650615                    3.0       0.130435   \n",
       "2              0.000000      1.000000                   15.0       1.000000   \n",
       "3              0.131009      0.650615                   17.0       0.125000   \n",
       "4              0.131009      0.650615                   15.0       0.333333   \n",
       "\n",
       "   anciennete  recence_cmd        AGE  \n",
       "0      1550.0         36.0  36.772698  \n",
       "1      1667.0         25.0  35.000000  \n",
       "2       395.0         15.0  25.000000  \n",
       "3      2188.0         20.0  31.000000  \n",
       "4      3005.0         15.0  32.000000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_frame.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ou en utilisant une compréhension de dictionnaire\n",
    "#my_dict = {data3.groupBy().avg(\"Age\").take(1)[0][0] for i in continuous}\n",
    "#print(my_dict)\n",
    "#my_dict = {}\n",
    "#for word in lst_words:\n",
    "#    my_dict[cle(word)] = anagrammes(word)\n",
    "    \n",
    "#mean = data3.groupBy().avg(\"Age\").take(1)[0][0]\n",
    "#data3.withColumn(\"test\", lit(mean)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import lit\n",
    "\n",
    "#dic={}\n",
    "#for i in continuous:\n",
    "#    dic[i]= data3.groupBy().avg(i).take(1)[0][0]\n",
    "#print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_df(df):\n",
    "    ds = df.select('ID_CLIENT',\n",
    "    f.when(df.LBL_GEO_TRAIN.isin(['Toulouse', 'Lille', 'Dijon',\n",
    "                                  'Lyon', 'Marseille', 'Paris',\n",
    "                                  'Nice', 'Limoges','Rouen','Rennes',\n",
    "                                  'Montpellier', 'Bordeaux', 'Metz',\n",
    "                                  'Strasbourg']), df.LBL_GEO_TRAIN)\\\n",
    "               .otherwise('na').alias('geo_train'),\n",
    "    f.when(df.LBL_GEO_AIR.isin(['Aéroports de Paris Orly',\n",
    "                                'Aéroport de Bâle-Mulhouse / Bassel',\n",
    "                                'Aéroport Lille Lesquin', 'Aéroport de Rennes',\n",
    "                                'Aéroport de Nantes Atlantique',\n",
    "                                'Aéroport de Marseille Provence  (MRS)', \n",
    "                                'Aéroport de Bordeaux Mérignac',\n",
    "                                'Aéroports de Paris Roissy-Charles-de Gaulle', \n",
    "                                \"Aéroport de Nice Côte d'Azur\",\n",
    "                                'Aéroport de Strasbourg',\n",
    "                                'Aéroport de Lyon - Saint Exupéry', \n",
    "                                'Aéroport de Toulouse Blagnac']), df.LBL_GEO_AIR)\\\n",
    "               .otherwise('na').alias('geo_air'),\n",
    "    f.when(df.FLG_CMD_CARTE_1225 == '1', '1')\\\n",
    "                   .otherwise('0').alias('cc_jeunes'),\n",
    "    f.when(df.LBL_STATUT_CLT.isin(['Tres grand', 'Nouveau actif',\n",
    "                                   'Moyen moins', ' Prospect', ' Petit',\n",
    "                                   'Inactif', 'Tres petit',\n",
    "                                   'Nouveau prospect', 'Moyen plus',\n",
    "                                   'Grand']), df.LBL_STATUT_CLT)\\\n",
    "                   .otherwise('na').alias('segt_rfm'),\n",
    "    f.when(df.LBL_SEGMENT_ANTICIPATION.isin(['Peu Anticipateur', 'Tres Anticipateur',\n",
    "                                             'Anticipateur', 'Mixte', 'Non Anticipateur',\n",
    "                                             'Non Defini']), df.LBL_SEGMENT_ANTICIPATION)\\\n",
    "                   .otherwise('na').alias('segt_anticipation'),\n",
    "    f.when(df.LBL_SEG_COMPORTEMENTAL.isin(['Mono-commande',\n",
    "                                           'Comportement Pro',\n",
    "                                           'Exclusifs Agence', \n",
    "                                           'Anticipateurs Methodiques',\n",
    "                                           'Chasseurs Bons Plans', \n",
    "                                           'Rythmes scolaires', 'Nouveaux',\n",
    "                                           'Sans contraintes']),\n",
    "           df.LBL_SEG_COMPORTEMENTAL).otherwise('na').alias('segt_comportemental'), \n",
    "    f.when(df.LBL_GRP_SEGMENT_NL.isin(['Endormi', 'Spectateur', 'Acteur',\n",
    "                                       'Eteint', 'Non defini']),\n",
    "           df.LBL_GRP_SEGMENT_NL).otherwise('na').alias('segt_nl'),\n",
    "    f.when(((df.AGE > 0) & (df.AGE < 100)), df.AGE)\\\n",
    "                   .otherwise(-1).alias('age'),\n",
    "    f.when(df.recence_cmd >= 0, df.recence_cmd)\\\n",
    "                   .otherwise(-1).alias('recence_cmd'),\n",
    "    f.when(((df.mean_duree_voyage > 0) & (df.mean_duree_voyage < 750)),\n",
    "           df.mean_duree_voyage).otherwise(-1).alias('mean_duree_voyage'),\n",
    "    f.when(df.days_since_last_visit >= 0, df.days_since_last_visit)\\\n",
    "                   .otherwise(-1).alias('recence_visite'),\n",
    "    f.when(df.mean_mt_voyage > 0, df.mean_mt_voyage)\\\n",
    "                   .otherwise(-1).alias('mean_mt_voyage'),\n",
    "    f.when(df.anciennete >= 0, df.anciennete)\\\n",
    "                   .otherwise(-1).alias('anciennete'),\n",
    "    f.when(df.nb_od > 0, df.nb_od)\\\n",
    "                   .otherwise(-1).alias('nb_od'),\n",
    "    f.when(df.mean_nb_passagers > 0, df.mean_nb_passagers)\\\n",
    "                   .otherwise(-1).alias('mean_nb_passagers'),\n",
    "    f.when(df.mean_tarif_loisir >= 0, df.mean_tarif_loisir)\\\n",
    "                   .otherwise(-1).alias('mean_tarif_loisir'),\n",
    "    f.when(df.mean_classe_1 >= 0, df.mean_classe_1)\\\n",
    "                   .otherwise(-1).alias('mean_classe_1'),\n",
    "    f.when(df.mean_pointe >= 0, df.mean_pointe)\\\n",
    "                   .otherwise(-1).alias('mean_pointe'),\n",
    "    f.when(df.mean_depart_we >= 0, df.mean_depart_we)\\\n",
    "                   .otherwise(-1).alias('mean_depart_we'),\n",
    "    f.when(df.tx_conversion >= 0, df.tx_conversion)\\\n",
    "                   .otherwise(-1).alias('tx_conversion'),\n",
    "    f.when(df.flg_cmd_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_cmd_lowcost'),\n",
    "    f.when(df.flg_track_nl_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl_lowcost'), \n",
    "    f.when(df.flg_track_nl == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl'))\n",
    "    \n",
    "    return ds\n",
    "#df = input_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Quelles sont les differentes valeurs de notre label : flg_cmd_lowcost ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cette fonction retourne un dataframe en creant une colonne supplementaire\n",
    "pour sauuv les valeurs presentes a chaq etapes ,puis les non presentes par les na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'flg_cmd_lowcost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6fa6f8f8baa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#data_new.limit(3).toPandas()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#modalite(data_new,\"flg_cmd_lowcost\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-ed1b1714ea1e>\u001b[0m in \u001b[0;36minput_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtx_conversion\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtx_conversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                    \u001b[1;33m.\u001b[0m\u001b[0motherwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tx_conversion'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflg_cmd_lowcost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m                    \u001b[1;33m.\u001b[0m\u001b[0motherwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'flg_cmd_lowcost'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflg_track_nl_lowcost\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-2.4.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1298\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m             raise AttributeError(\n\u001b[1;32m-> 1300\u001b[1;33m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[0;32m   1301\u001b[0m         \u001b[0mjc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'flg_cmd_lowcost'"
     ]
    }
   ],
   "source": [
    "data_new = input_df(d_frame)\n",
    "#data_new.limit(3).toPandas()\n",
    "#modalite(data_new,\"flg_cmd_lowcost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Afficher l'effectif des différentes modalités de flg_cmd_lowcost du data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.groupby(\"flg_cmd_lowcost\").agg(f.count(\"flg_cmd_lowcost\").alias(\"Effectif\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.filter(ds.flg_cmd_lowcost=='1').count()\n",
    "#df.withColumn(\"adulte\", f.when(df[\"age\"] < 25, 0).when(df[\"age\"] >= 25,1)).toPandas()\n",
    "#d.withColumn(\"Total\", f.count(\"Effectif\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail du dataframe datanew\n",
    "dtail_data(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering et modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocessed_df(df, label=\"flg_cmd_lowcostIndex\"):\n",
    "    max_values_to_define_str_cols = 10\n",
    "    id_col = 'ID_CLIENT'\n",
    "    \n",
    "    dty = dict(df.dtypes)\n",
    "    str_cols = [k for k, v in dty.items() if v == 'string']\n",
    "    str_cols.remove(id_col)\n",
    "    \n",
    "    for c in str_cols:\n",
    "        stringIndexer = StringIndexer(inputCol=c, outputCol=c+\"Index\")\n",
    "        model_str = stringIndexer.fit(df)\n",
    "        df = model_str.transform(df).drop(c)\n",
    "\n",
    "    input_cols = df.columns\n",
    "    input_cols.remove(id_col)\n",
    "    input_cols.remove(label)\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=input_cols,\n",
    "                            outputCol=\"features\")\n",
    "    df = assembler.transform(df)\n",
    "    \n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                   outputCol=\"indexedFeatures\", \n",
    "                   maxCategories=max_values_to_define_str_cols).fit(df)\n",
    "    return featureIndexer.transform(df), df\n",
    "\n",
    "\n",
    "data, dff = preprocessed_df(data_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtail_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtail_data(dff) #test indexedFeatures: vector??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelever un sample de data pour notre modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction du modele avec 70% des donnees en apprentissage\n",
    "Xtrain = data.sample(False, 0.7, 42)\n",
    "Xval = data.subtract(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quelle est le label est renseigne pour la modelisation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_log = LogisticRegression(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                        featuresCol=\"indexedFeatures\",elasticNetParam=0.5)\n",
    "\n",
    "my_model = reg_log.fit(Xtrain)\n",
    "\n",
    "my_predict = my_model.evaluate(Xval) #prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ajuster le modele de regression logistique et calculer les coefficients de notre modele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluer votre modele courbe roc, precision, rappel, etc....**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predict.areaUnderROC # renvoie l AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predire alors les clients lowcoast sur un sample de data n'ayant pas servi à l'apprentissage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                                    featuresCol=\"indexedFeatures\",\n",
    "                                    maxDepth=15, numTrees=100)\n",
    "\n",
    "model_rf = classifier.fit(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluer les performance de notre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# une autre technique pour evaluer le modele\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluer soit meme le score en calculant le nombre de VP, FP, VN et FN\n",
    "on calculera alors le score qui VP+VN/VP+VN+FP+FN\n",
    "nb: la prediction est automatiquement creee dans le data set et correspond à la colonne prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6846384667505566, 1.0, 0.9699609990872127)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculer egalement le rappel et la precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(raw=DenseVector([0.9, 0.1]), label=0.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "scoreAndLabels = map(lambda x: (Vectors.dense([1.0 - x[0], x[0]]), x[1]),\n",
    "                     [(0.1, 0.0), (0.1, 1.0), (0.4, 0.0), (0.6, 0.0), (0.6, 1.0), (0.6, 1.0), (0.8, 1.0)])\n",
    "dataset = spark_session.createDataFrame(scoreAndLabels, [\"raw\", \"label\"])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a spark data frame ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Ankit</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>Jalfaizy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>saurabh</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>Bala</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>Jules</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>Arild</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>sarah</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>Boly</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>Anita</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>Jules</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>Soul</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>Gral</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>Apoh</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Dony</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>Tanoh</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Issouf</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Bilé</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>Gagnon</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>Papiss</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Kravitz</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Mouli</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>Jacques</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>soum</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36</td>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>MBra</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age        date      name    sexe\n",
       "0    25  2018-01-03     Ankit  Female\n",
       "1    22  2018-02-03  Jalfaizy  Female\n",
       "2    20  2018-01-05   saurabh  Female\n",
       "3    26  2018-01-12      Bala  Female\n",
       "4    19  2018-07-09     Jules  Female\n",
       "5    43  2018-03-18     Arild    Male\n",
       "6    20  2018-01-05     sarah    Male\n",
       "7    33  2018-08-12      Boly    Male\n",
       "8    35  2018-04-06     Anita    Male\n",
       "9    22  2018-12-06     Jules    Male\n",
       "10   20  2018-07-24      Soul  Female\n",
       "11   54  2018-06-17      Gral  Female\n",
       "12   18  2018-09-07      Apoh  Female\n",
       "13   32  2018-10-04      Dony  Female\n",
       "14   31  2018-02-05     Tanoh  Female\n",
       "15   27  2018-11-12    Issouf    Male\n",
       "16   29  2018-10-03      Bilé    Male\n",
       "17   20  2018-05-03    Gagnon    Male\n",
       "18   28  2018-03-05    Papiss    Male\n",
       "19   34  2018-02-12   Kravitz    Male\n",
       "20   35  2018-05-09     Mouli  Female\n",
       "21   27  2018-08-03   Jacques  Female\n",
       "22   22  2018-12-05      soum  Female\n",
       "23   36  2018-04-12      MBra  Female"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "import datetime\n",
    "\n",
    "l = [(datetime.date(2018,1,3), 'Ankit',25,'Female'),\n",
    "     (datetime.date(2018,2,3), 'Jalfaizy',22,'Female'),\n",
    "     (datetime.date(2018,1,5), 'saurabh',20,'Female'),\n",
    "     (datetime.date(2018,1,12), 'Bala',26,'Female'),\n",
    "     (datetime.date(2018,7,9), 'Jules',19,'Female') ,\n",
    "     (datetime.date(2018,3,18), 'Arild',43,'Male'),\n",
    "     (datetime.date(2018,1,5), 'sarah',20,'Male'),\n",
    "     (datetime.date(2018,8,12), 'Boly',33,'Male'),\n",
    "     (datetime.date(2018,4,6), 'Anita',35,'Male'),\n",
    "     (datetime.date(2018,12,6), 'Jules',22,'Male'),\n",
    "     (datetime.date(2018,7,24), 'Soul',20,'Female'),\n",
    "     (datetime.date(2018,6,17), 'Gral',54,'Female'),\n",
    "     (datetime.date(2018,9,7), 'Apoh',18,'Female'),\n",
    "     (datetime.date(2018,10,4), 'Dony',32,'Female'),\n",
    "     (datetime.date(2018,2,5), 'Tanoh',31,'Female'),\n",
    "     (datetime.date(2018,11,12), 'Issouf',27,'Male'),\n",
    "     (datetime.date(2018,10,3), 'Bilé',29,'Male'),\n",
    "     (datetime.date(2018,5,3), 'Gagnon',20,'Male'),\n",
    "     (datetime.date(2018,3,5), 'Papiss',28,'Male'),\n",
    "     (datetime.date(2018,2,12), 'Kravitz',34,'Male'),\n",
    "     (datetime.date(2018,5,9), 'Mouli',35,'Female'),\n",
    "     (datetime.date(2018,8,3), 'Jacques',27,'Female'),\n",
    "     (datetime.date(2018,12,5), 'soum',22,'Female'),\n",
    "     (datetime.date(2018,4,12), 'MBra',36,'Female'),]\n",
    "\n",
    "rdd = spark_session.sparkContext.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(date=x[0], name=x[1], age=int(x[2]),sexe=x[3]))\n",
    "schemaPeople = spark_session.createDataFrame(people)\n",
    "schemaPeople.toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- compter le nombre de personne totale \n",
    "2- compter le nombre de fille et de garcon\n",
    "3- quel est l'age moyen, median mini et maxi dans chaque groupe (garcon, fille)\n",
    "4 - quelle est la date de dernière visite de chaque client par rapport à la date d'aujourd'hui (la colonne date correspond à la date de visite)\n",
    "5 - quels sont les personnes qui ont une date de visite < 400 jours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1- compter le nombre de personne totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaPeople.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2- Compter le nombre de fille et de garcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  sexe|Effectif|\n",
      "+------+--------+\n",
      "|Female|      14|\n",
      "|  Male|      10|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.groupby(\"sexe\").agg(f.count(\"sexe\").alias(\"Effectif\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3- Quel est l'age moyen, median mini et maxi dans chaque groupe (garcon, fille) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+-------+-------+\n",
      "|  sexe|Effectif|               Moy|Age Min|Age Max|\n",
      "+------+--------+------------------+-------+-------+\n",
      "|Female|      14|27.642857142857142|     18|     54|\n",
      "|  Male|      10|              29.1|     20|     43|\n",
      "+------+--------+------------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.groupby([\"sexe\"]).describe()\n",
    "schemaPeople.groupby(\"sexe\").agg(\n",
    "     f.count(\"sexe\").alias(\"Effectif\"),\n",
    "     f.mean(\"age\").alias(\"Moy\"),  \n",
    "     f.min(\"age\").alias(\"Age Min\"),\n",
    "     f.max(\"age\").alias(\"Age Max\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-a11e861cf24f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m medi = [('G',schemaPeople.filter(schemaPeople['sexe'] == 'G').approxQuantile('age',(0.5,),0.001)[0],),\n\u001b[0m\u001b[0;32m      2\u001b[0m ('F',schemaPeople.filter(schemaPeople['sexe'] == 'F').approxQuantile('age',(0.5,),0.001)[0],)]\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msexe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmediane\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "medi = [('G',schemaPeople.filter(schemaPeople['sexe'] == 'G').approxQuantile('age',(0.5,),0.001)[0],),\n",
    "('F',schemaPeople.filter(schemaPeople['sexe'] == 'F').approxQuantile('age',(0.5,),0.001)[0],)]\n",
    "\n",
    "rdd = spark_session.sparkContext.parallelize(medi)\n",
    "med = rdd.map(lambda x: Row(sexe = x[0], mediane=x[1]))\n",
    "schemaMedian = spark_session.createDataFrame(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaMedian.join(other, on = 'sexe').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4 - Quelle est la durée de visite de chaque client depuis sa dernière date visite jusqu'à la date d'aujourd'hui ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = schemaPeople.select(\"*\",\n",
    "                         f.lit(datetime.date.today()).alias(\"date_max\"))\n",
    "dd.select(\"*\", f.datediff('date_max', 'date')\\\n",
    "                    .alias('days_since_last_visit')).toPandas()\n",
    "\n",
    "#dd2 = spark_session.createDataFrame(dd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.groupby(\"name\").agg(f.count(\"sexe\").alias(\"Effectif\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.select(\"*\", (f.datediff('date_max', 'date')<400).alias('Boolean'))\n",
    "\n",
    "df.groupby(\"Boolean\").agg(f.count(\"Boolean\").alias(\"last date ago<400\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.filter(df[\"sexe\"].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in dd.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan\n",
    "dd.filter((dd[\"sexe\"] == \"\") | dd[\"sexe\"].isNull() | isnan(dd[\"sexe\"])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.select([f.count(f.when(f.isnan(c), c)).alias(\"missing_\"+ c)\n",
    "                    for c in dd.columns if c not in [\"date\", \"date_max\"] ]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 7 -Ajout de colonne correspondant a chaque mois de chaque ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = schemaPeople.select(\"*\", f.month('date').alias('mois'))\n",
    "df2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 8- Créer une colonne adulte qui prendra la valeur 0 pour les personnes de moins de 25 ans et 1 dans le cas contraire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"adulte\", f.when(df[\"age\"] < 25, 0).when(df[\"age\"] >= 25,1)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
